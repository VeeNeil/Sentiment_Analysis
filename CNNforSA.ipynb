{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-09-30T11:17:05.095613Z",
     "end_time": "2023-09-30T11:17:05.110611Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras.utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.losses import binary_crossentropy\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Bidirectional, LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from wittgenstein import RIPPER\n",
    "from wittgenstein.interpret import interpret_model, score_fidelity\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data = pd.read_csv('TV.csv')\n",
    "\n",
    "# # Split the data into training and validation sets\n",
    "X = data['Nhận xét đánh giá'].values\n",
    "y = data['Cảm xúc'].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Encode the labels\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-30T11:17:05.103612Z",
     "end_time": "2023-09-30T11:17:05.224613Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "max_words = 5000  # Maximum number of words to consider\n",
    "max_len = 1000  # Maximum length of a sequence\n",
    "\n",
    "\n",
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "X_train_seq = keras.utils.pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_val_seq = keras.utils.pad_sequences(X_val_seq, maxlen=max_len)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-30T11:17:05.227617Z",
     "end_time": "2023-09-30T11:17:05.904611Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "embedding_dim = 120  # Dimensionality of word embeddings\n",
    "num_filters = 128  # Number of filters in the convolutional layer\n",
    "kernel_size = 5\n",
    "num_classes = len(label_encoder.classes_)  # Number of output classes\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=max_len))\n",
    "model.add(Conv1D(num_filters, kernel_size, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-30T11:17:05.906612Z",
     "end_time": "2023-09-30T11:17:06.302224Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "208/208 [==============================] - 72s 341ms/step - loss: 0.9580 - accuracy: 0.6203 - val_loss: 0.7980 - val_accuracy: 0.6919\n",
      "Epoch 2/10\n",
      "208/208 [==============================] - 61s 294ms/step - loss: 0.7162 - accuracy: 0.7281 - val_loss: 0.7464 - val_accuracy: 0.7108\n",
      "Epoch 3/10\n",
      "208/208 [==============================] - 62s 296ms/step - loss: 0.6363 - accuracy: 0.7676 - val_loss: 0.7450 - val_accuracy: 0.7133\n",
      "Epoch 4/10\n",
      "208/208 [==============================] - 60s 291ms/step - loss: 0.5733 - accuracy: 0.7939 - val_loss: 0.7730 - val_accuracy: 0.7139\n",
      "Epoch 5/10\n",
      "208/208 [==============================] - 61s 293ms/step - loss: 0.5190 - accuracy: 0.8170 - val_loss: 0.7780 - val_accuracy: 0.7160\n",
      "Epoch 6/10\n",
      "208/208 [==============================] - 61s 292ms/step - loss: 0.4711 - accuracy: 0.8384 - val_loss: 0.7990 - val_accuracy: 0.7120\n",
      "Epoch 7/10\n",
      "208/208 [==============================] - 60s 290ms/step - loss: 0.4334 - accuracy: 0.8539 - val_loss: 0.8364 - val_accuracy: 0.7069\n",
      "Epoch 8/10\n",
      "208/208 [==============================] - 60s 287ms/step - loss: 0.4056 - accuracy: 0.8612 - val_loss: 0.8608 - val_accuracy: 0.7003\n",
      "Epoch 9/10\n",
      "208/208 [==============================] - 61s 295ms/step - loss: 0.3804 - accuracy: 0.8690 - val_loss: 0.8979 - val_accuracy: 0.7051\n",
      "Epoch 10/10\n",
      "208/208 [==============================] - 60s 290ms/step - loss: 0.3635 - accuracy: 0.8747 - val_loss: 0.9290 - val_accuracy: 0.6946\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x1c89947b5e0>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 10\n",
    "\n",
    "model.fit(X_train_seq, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val_seq, y_val))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-30T11:17:06.300222Z",
     "end_time": "2023-09-30T11:27:24.707662Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 3s 33ms/step - loss: 0.9290 - accuracy: 0.6946\n",
      "Validation loss: 0.929019570350647\n",
      "Validation accuracy: 0.6945782899856567\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_val_seq, y_val)\n",
    "print(f\"Validation loss: {loss}\")\n",
    "print(f\"Validation accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-30T11:27:24.710663Z",
     "end_time": "2023-09-30T11:27:28.177662Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/415 [==========>...................] - ETA: 13s"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(padded_sequences)\n",
    "\n",
    "cnn_feature_extractor = Sequential()\n",
    "cnn_feature_extractor.add(model.layers[0])  # Add layers up to the desired intermediate layer\n",
    "cnn_feature_extractor.add(model.layers[1])  # Add more layers if needed\n",
    "\n",
    "# Extract features from the intermediate CNN layer\n",
    "X_train_cnn_features = cnn_feature_extractor.predict(X_train_seq)\n",
    "X_val_cnn_features = cnn_feature_extractor.predict(X_val_seq)\n",
    "\n",
    "# 3. Train the RIPPER model on the extracted features\n",
    "ripper_classifier = RIPPER()\n",
    "ripper_classifier.fit(X_train_cnn_features, y_train)\n",
    "\n",
    "# 4. Combine predictions from CNN and RIPPER (you can adjust this part as needed)\n",
    "cnn_predictions = model.predict(X_val_seq)\n",
    "ripper_predictions = ripper_classifier.predict(X_val_cnn_features)\n",
    "\n",
    "# You can use some combination strategy to merge predictions (e.g., weighted average)\n",
    "combined_predictions = 0.7 * cnn_predictions + 0.3 * ripper_predictions\n",
    "\n",
    "# Evaluate the combined predictions\n",
    "combined_loss, combined_accuracy = model.evaluate(X_val_seq, combined_predictions)\n",
    "print(f\"Combined Validation loss: {combined_loss}\")\n",
    "print(f\"Combined Validation accuracy: {combined_accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T10:30:11.477800Z",
     "end_time": "2023-09-21T10:30:15.310320Z"
    },
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val_seq)\n",
    "# Convert numerical labels to original labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_labels)\n",
    "\n",
    "# Convert true labels to original labels\n",
    "y_val_labels = label_encoder.inverse_transform(y_val)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_val_labels, y_pred_labels)\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T23:17:50.417746Z",
     "end_time": "2023-09-21T23:18:00.521246Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-21T10:28:26.036693Z",
     "end_time": "2023-09-21T10:28:26.079319Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
