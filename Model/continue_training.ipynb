{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../ds/Team/team.csv')\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X_new = data['Nhận xét'].astype(str).values\n",
    "y_new = data['Cảm xúc'].values\n",
    "\n",
    "data['Cảm xúc'] = data['Cảm xúc'].str.strip()\n",
    "data.to_csv('team.csv', index=False)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_label =label_encoder.fit_transform(y_new)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_new, y_label, test_size=0.2, random_state=132)\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_val_encoded = to_categorical(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_words = 5000\n",
    "max_len = 1000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "X_train_seq = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_val_seq = pad_sequences(X_val_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1000, 120)         600000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 996, 128)          76928     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 677,702\n",
      "Trainable params: 677,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the pre-trained model\n",
    "pretrained_model = tf.keras.models.load_model('../saved_model/sentiment_model.keras')\n",
    "\n",
    "pretrained_model.summary()\n",
    "\n",
    "for layer in pretrained_model.layers[:2]:  \n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compile the model with the same optimizer and loss function\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "pretrained_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "161/161 [==============================] - 35s 211ms/step - loss: 2.7126 - accuracy: 0.2795 - val_loss: 2.1188 - val_accuracy: 0.3210\n",
      "Epoch 2/100\n",
      "161/161 [==============================] - 34s 214ms/step - loss: 1.9163 - accuracy: 0.3488 - val_loss: 1.6714 - val_accuracy: 0.3560\n",
      "Epoch 3/100\n",
      "161/161 [==============================] - 33s 208ms/step - loss: 1.5778 - accuracy: 0.4884 - val_loss: 1.4165 - val_accuracy: 0.5227\n",
      "Epoch 4/100\n",
      "161/161 [==============================] - 33s 205ms/step - loss: 1.3776 - accuracy: 0.5507 - val_loss: 1.2601 - val_accuracy: 0.5783\n",
      "Epoch 5/100\n",
      "161/161 [==============================] - 35s 220ms/step - loss: 1.2481 - accuracy: 0.5807 - val_loss: 1.1591 - val_accuracy: 0.6016\n",
      "Epoch 6/100\n",
      "161/161 [==============================] - 36s 224ms/step - loss: 1.1553 - accuracy: 0.5986 - val_loss: 1.0860 - val_accuracy: 0.6113\n",
      "Epoch 7/100\n",
      "161/161 [==============================] - 36s 225ms/step - loss: 1.0850 - accuracy: 0.6164 - val_loss: 1.0325 - val_accuracy: 0.6331\n",
      "Epoch 8/100\n",
      "161/161 [==============================] - 36s 223ms/step - loss: 1.0305 - accuracy: 0.6297 - val_loss: 0.9882 - val_accuracy: 0.6424\n",
      "Epoch 9/100\n",
      "161/161 [==============================] - 36s 227ms/step - loss: 0.9875 - accuracy: 0.6438 - val_loss: 0.9568 - val_accuracy: 0.6553\n",
      "Epoch 10/100\n",
      "161/161 [==============================] - 36s 226ms/step - loss: 0.9528 - accuracy: 0.6709 - val_loss: 0.9279 - val_accuracy: 0.6984\n",
      "Epoch 11/100\n",
      "161/161 [==============================] - 36s 224ms/step - loss: 0.9245 - accuracy: 0.6997 - val_loss: 0.9048 - val_accuracy: 0.7038\n",
      "Epoch 12/100\n",
      "161/161 [==============================] - 36s 226ms/step - loss: 0.8998 - accuracy: 0.7108 - val_loss: 0.8884 - val_accuracy: 0.7101\n",
      "Epoch 13/100\n",
      "161/161 [==============================] - 36s 225ms/step - loss: 0.8795 - accuracy: 0.7147 - val_loss: 0.8701 - val_accuracy: 0.7058\n",
      "Epoch 14/100\n",
      "161/161 [==============================] - 35s 218ms/step - loss: 0.8623 - accuracy: 0.7170 - val_loss: 0.8544 - val_accuracy: 0.7120\n",
      "Epoch 15/100\n",
      "161/161 [==============================] - 35s 217ms/step - loss: 0.8467 - accuracy: 0.7200 - val_loss: 0.8432 - val_accuracy: 0.7159\n",
      "Epoch 16/100\n",
      "161/161 [==============================] - 35s 219ms/step - loss: 0.8334 - accuracy: 0.7231 - val_loss: 0.8323 - val_accuracy: 0.7155\n",
      "Epoch 17/100\n",
      "161/161 [==============================] - 35s 216ms/step - loss: 0.8216 - accuracy: 0.7269 - val_loss: 0.8222 - val_accuracy: 0.7194\n",
      "Epoch 18/100\n",
      "161/161 [==============================] - 35s 216ms/step - loss: 0.8106 - accuracy: 0.7304 - val_loss: 0.8112 - val_accuracy: 0.7178\n",
      "Epoch 19/100\n",
      "161/161 [==============================] - 39s 241ms/step - loss: 0.8011 - accuracy: 0.7323 - val_loss: 0.8043 - val_accuracy: 0.7244\n",
      "Epoch 20/100\n",
      "161/161 [==============================] - 48s 297ms/step - loss: 0.7922 - accuracy: 0.7359 - val_loss: 0.7957 - val_accuracy: 0.7256\n",
      "Epoch 21/100\n",
      "161/161 [==============================] - 78s 489ms/step - loss: 0.7843 - accuracy: 0.7401 - val_loss: 0.7880 - val_accuracy: 0.7268\n",
      "Epoch 22/100\n",
      "161/161 [==============================] - 43s 263ms/step - loss: 0.7767 - accuracy: 0.7404 - val_loss: 0.7817 - val_accuracy: 0.7334\n",
      "Epoch 23/100\n",
      "161/161 [==============================] - 37s 232ms/step - loss: 0.7699 - accuracy: 0.7415 - val_loss: 0.7770 - val_accuracy: 0.7318\n",
      "Epoch 24/100\n",
      "161/161 [==============================] - 36s 224ms/step - loss: 0.7640 - accuracy: 0.7441 - val_loss: 0.7707 - val_accuracy: 0.7353\n",
      "Epoch 25/100\n",
      "161/161 [==============================] - 36s 222ms/step - loss: 0.7577 - accuracy: 0.7436 - val_loss: 0.7684 - val_accuracy: 0.7357\n",
      "Epoch 26/100\n",
      "161/161 [==============================] - 36s 221ms/step - loss: 0.7526 - accuracy: 0.7468 - val_loss: 0.7617 - val_accuracy: 0.7369\n",
      "Epoch 27/100\n",
      "161/161 [==============================] - 35s 221ms/step - loss: 0.7467 - accuracy: 0.7470 - val_loss: 0.7567 - val_accuracy: 0.7396\n",
      "Epoch 28/100\n",
      "161/161 [==============================] - 35s 218ms/step - loss: 0.7430 - accuracy: 0.7479 - val_loss: 0.7540 - val_accuracy: 0.7408\n",
      "Epoch 29/100\n",
      "161/161 [==============================] - 35s 215ms/step - loss: 0.7386 - accuracy: 0.7493 - val_loss: 0.7511 - val_accuracy: 0.7447\n",
      "Epoch 30/100\n",
      "161/161 [==============================] - 34s 213ms/step - loss: 0.7345 - accuracy: 0.7511 - val_loss: 0.7471 - val_accuracy: 0.7415\n",
      "Epoch 31/100\n",
      "161/161 [==============================] - 34s 209ms/step - loss: 0.7302 - accuracy: 0.7503 - val_loss: 0.7446 - val_accuracy: 0.7423\n",
      "Epoch 32/100\n",
      "161/161 [==============================] - 34s 210ms/step - loss: 0.7271 - accuracy: 0.7520 - val_loss: 0.7396 - val_accuracy: 0.7439\n",
      "Epoch 33/100\n",
      "161/161 [==============================] - 33s 208ms/step - loss: 0.7238 - accuracy: 0.7550 - val_loss: 0.7363 - val_accuracy: 0.7656\n",
      "Epoch 34/100\n",
      "161/161 [==============================] - 44s 277ms/step - loss: 0.7200 - accuracy: 0.7606 - val_loss: 0.7350 - val_accuracy: 0.7450\n",
      "Epoch 35/100\n",
      "161/161 [==============================] - 33s 208ms/step - loss: 0.7174 - accuracy: 0.7580 - val_loss: 0.7312 - val_accuracy: 0.7664\n",
      "Epoch 36/100\n",
      "161/161 [==============================] - 32s 198ms/step - loss: 0.7141 - accuracy: 0.7627 - val_loss: 0.7296 - val_accuracy: 0.7505\n",
      "Epoch 37/100\n",
      "161/161 [==============================] - 31s 192ms/step - loss: 0.7114 - accuracy: 0.7632 - val_loss: 0.7267 - val_accuracy: 0.7711\n",
      "Epoch 38/100\n",
      "161/161 [==============================] - 31s 193ms/step - loss: 0.7092 - accuracy: 0.7696 - val_loss: 0.7244 - val_accuracy: 0.7699\n",
      "Epoch 39/100\n",
      "161/161 [==============================] - 31s 190ms/step - loss: 0.7069 - accuracy: 0.7679 - val_loss: 0.7224 - val_accuracy: 0.7711\n",
      "Epoch 40/100\n",
      "161/161 [==============================] - 31s 190ms/step - loss: 0.7044 - accuracy: 0.7706 - val_loss: 0.7220 - val_accuracy: 0.7548\n",
      "Epoch 41/100\n",
      "161/161 [==============================] - 31s 191ms/step - loss: 0.7017 - accuracy: 0.7734 - val_loss: 0.7205 - val_accuracy: 0.7746\n",
      "Epoch 42/100\n",
      "161/161 [==============================] - 31s 192ms/step - loss: 0.6995 - accuracy: 0.7743 - val_loss: 0.7168 - val_accuracy: 0.7719\n",
      "Epoch 43/100\n",
      "161/161 [==============================] - 31s 192ms/step - loss: 0.6976 - accuracy: 0.7735 - val_loss: 0.7169 - val_accuracy: 0.7746\n",
      "Epoch 44/100\n",
      "161/161 [==============================] - 31s 195ms/step - loss: 0.6967 - accuracy: 0.7732 - val_loss: 0.7140 - val_accuracy: 0.7742\n",
      "Epoch 45/100\n",
      "161/161 [==============================] - 31s 192ms/step - loss: 0.6939 - accuracy: 0.7768 - val_loss: 0.7116 - val_accuracy: 0.7734\n",
      "Epoch 46/100\n",
      "161/161 [==============================] - 31s 191ms/step - loss: 0.6923 - accuracy: 0.7756 - val_loss: 0.7100 - val_accuracy: 0.7746\n",
      "Epoch 47/100\n",
      "161/161 [==============================] - 31s 193ms/step - loss: 0.6905 - accuracy: 0.7774 - val_loss: 0.7106 - val_accuracy: 0.7777\n",
      "Epoch 48/100\n",
      "161/161 [==============================] - 30s 188ms/step - loss: 0.6888 - accuracy: 0.7784 - val_loss: 0.7080 - val_accuracy: 0.7742\n",
      "Epoch 49/100\n",
      "161/161 [==============================] - 32s 200ms/step - loss: 0.6867 - accuracy: 0.7790 - val_loss: 0.7069 - val_accuracy: 0.7734\n",
      "Epoch 50/100\n",
      "161/161 [==============================] - 33s 204ms/step - loss: 0.6860 - accuracy: 0.7777 - val_loss: 0.7056 - val_accuracy: 0.7781\n",
      "Epoch 51/100\n",
      "161/161 [==============================] - 34s 209ms/step - loss: 0.6838 - accuracy: 0.7788 - val_loss: 0.7030 - val_accuracy: 0.7757\n",
      "Epoch 52/100\n",
      "161/161 [==============================] - 33s 208ms/step - loss: 0.6824 - accuracy: 0.7774 - val_loss: 0.7019 - val_accuracy: 0.7757\n",
      "Epoch 53/100\n",
      "161/161 [==============================] - 33s 208ms/step - loss: 0.6810 - accuracy: 0.7790 - val_loss: 0.7019 - val_accuracy: 0.7777\n",
      "Epoch 54/100\n",
      "161/161 [==============================] - 33s 208ms/step - loss: 0.6799 - accuracy: 0.7810 - val_loss: 0.7002 - val_accuracy: 0.7777\n",
      "Epoch 55/100\n",
      "161/161 [==============================] - 33s 207ms/step - loss: 0.6786 - accuracy: 0.7799 - val_loss: 0.7003 - val_accuracy: 0.7796\n",
      "Epoch 56/100\n",
      "161/161 [==============================] - 33s 208ms/step - loss: 0.6767 - accuracy: 0.7805 - val_loss: 0.6983 - val_accuracy: 0.7789\n",
      "Epoch 57/100\n",
      "161/161 [==============================] - 33s 206ms/step - loss: 0.6760 - accuracy: 0.7794 - val_loss: 0.6974 - val_accuracy: 0.7781\n",
      "Epoch 58/100\n",
      "161/161 [==============================] - 33s 205ms/step - loss: 0.6747 - accuracy: 0.7807 - val_loss: 0.6961 - val_accuracy: 0.7746\n",
      "Epoch 59/100\n",
      "161/161 [==============================] - 33s 204ms/step - loss: 0.6731 - accuracy: 0.7818 - val_loss: 0.6960 - val_accuracy: 0.7769\n",
      "Epoch 60/100\n",
      "161/161 [==============================] - 33s 204ms/step - loss: 0.6730 - accuracy: 0.7811 - val_loss: 0.6933 - val_accuracy: 0.7773\n",
      "Epoch 61/100\n",
      "161/161 [==============================] - 34s 210ms/step - loss: 0.6709 - accuracy: 0.7812 - val_loss: 0.6935 - val_accuracy: 0.7785\n",
      "Epoch 62/100\n",
      "161/161 [==============================] - 41s 252ms/step - loss: 0.6707 - accuracy: 0.7822 - val_loss: 0.6910 - val_accuracy: 0.7773\n",
      "Epoch 63/100\n",
      "161/161 [==============================] - 37s 231ms/step - loss: 0.6688 - accuracy: 0.7828 - val_loss: 0.6901 - val_accuracy: 0.7777\n",
      "Epoch 64/100\n",
      "161/161 [==============================] - 41s 255ms/step - loss: 0.6686 - accuracy: 0.7840 - val_loss: 0.6903 - val_accuracy: 0.7785\n",
      "Epoch 65/100\n",
      "161/161 [==============================] - 39s 240ms/step - loss: 0.6674 - accuracy: 0.7815 - val_loss: 0.6909 - val_accuracy: 0.7785\n",
      "Epoch 66/100\n",
      "161/161 [==============================] - 37s 229ms/step - loss: 0.6664 - accuracy: 0.7844 - val_loss: 0.6875 - val_accuracy: 0.7789\n",
      "Epoch 67/100\n",
      "161/161 [==============================] - 36s 226ms/step - loss: 0.6653 - accuracy: 0.7861 - val_loss: 0.6898 - val_accuracy: 0.7738\n",
      "Epoch 68/100\n",
      "161/161 [==============================] - 49s 303ms/step - loss: 0.6646 - accuracy: 0.7834 - val_loss: 0.6877 - val_accuracy: 0.7785\n",
      "Epoch 69/100\n",
      "161/161 [==============================] - 41s 254ms/step - loss: 0.6636 - accuracy: 0.7861 - val_loss: 0.6873 - val_accuracy: 0.7777\n",
      "Epoch 70/100\n",
      "161/161 [==============================] - 39s 244ms/step - loss: 0.6625 - accuracy: 0.7857 - val_loss: 0.6855 - val_accuracy: 0.7831\n",
      "Epoch 71/100\n",
      "161/161 [==============================] - 37s 233ms/step - loss: 0.6621 - accuracy: 0.7842 - val_loss: 0.6847 - val_accuracy: 0.7808\n",
      "Epoch 72/100\n",
      "161/161 [==============================] - 41s 257ms/step - loss: 0.6613 - accuracy: 0.7847 - val_loss: 0.6851 - val_accuracy: 0.7820\n",
      "Epoch 73/100\n",
      "161/161 [==============================] - 35s 217ms/step - loss: 0.6596 - accuracy: 0.7854 - val_loss: 0.6848 - val_accuracy: 0.7789\n",
      "Epoch 74/100\n",
      "161/161 [==============================] - 35s 217ms/step - loss: 0.6595 - accuracy: 0.7871 - val_loss: 0.6838 - val_accuracy: 0.7824\n",
      "Epoch 75/100\n",
      "161/161 [==============================] - 33s 206ms/step - loss: 0.6586 - accuracy: 0.7869 - val_loss: 0.6820 - val_accuracy: 0.7785\n",
      "Epoch 76/100\n",
      "161/161 [==============================] - 35s 215ms/step - loss: 0.6576 - accuracy: 0.7862 - val_loss: 0.6824 - val_accuracy: 0.7831\n",
      "Epoch 77/100\n",
      "161/161 [==============================] - 34s 211ms/step - loss: 0.6570 - accuracy: 0.7860 - val_loss: 0.6802 - val_accuracy: 0.7808\n",
      "Epoch 78/100\n",
      "161/161 [==============================] - 46s 285ms/step - loss: 0.6564 - accuracy: 0.7861 - val_loss: 0.6800 - val_accuracy: 0.7820\n",
      "Epoch 79/100\n",
      "161/161 [==============================] - 48s 297ms/step - loss: 0.6558 - accuracy: 0.7872 - val_loss: 0.6798 - val_accuracy: 0.7816\n",
      "Epoch 80/100\n",
      "161/161 [==============================] - 35s 216ms/step - loss: 0.6547 - accuracy: 0.7885 - val_loss: 0.6799 - val_accuracy: 0.7839\n",
      "Epoch 81/100\n",
      "161/161 [==============================] - 32s 197ms/step - loss: 0.6543 - accuracy: 0.7878 - val_loss: 0.6779 - val_accuracy: 0.7804\n",
      "Epoch 82/100\n",
      "161/161 [==============================] - 33s 202ms/step - loss: 0.6537 - accuracy: 0.7879 - val_loss: 0.6780 - val_accuracy: 0.7839\n",
      "Epoch 83/100\n",
      "161/161 [==============================] - 33s 203ms/step - loss: 0.6531 - accuracy: 0.7882 - val_loss: 0.6782 - val_accuracy: 0.7800\n",
      "Epoch 84/100\n",
      "161/161 [==============================] - 32s 201ms/step - loss: 0.6520 - accuracy: 0.7876 - val_loss: 0.6763 - val_accuracy: 0.7816\n",
      "Epoch 85/100\n",
      "161/161 [==============================] - 40s 249ms/step - loss: 0.6511 - accuracy: 0.7880 - val_loss: 0.6763 - val_accuracy: 0.7820\n",
      "Epoch 86/100\n",
      "161/161 [==============================] - 44s 276ms/step - loss: 0.6504 - accuracy: 0.7881 - val_loss: 0.6765 - val_accuracy: 0.7796\n",
      "Epoch 87/100\n",
      "161/161 [==============================] - 45s 279ms/step - loss: 0.6501 - accuracy: 0.7900 - val_loss: 0.6778 - val_accuracy: 0.7804\n",
      "Epoch 88/100\n",
      "161/161 [==============================] - 41s 252ms/step - loss: 0.6497 - accuracy: 0.7884 - val_loss: 0.6746 - val_accuracy: 0.7824\n",
      "Epoch 89/100\n",
      "161/161 [==============================] - 35s 219ms/step - loss: 0.6491 - accuracy: 0.7880 - val_loss: 0.6751 - val_accuracy: 0.7839\n",
      "Epoch 90/100\n",
      "161/161 [==============================] - 35s 220ms/step - loss: 0.6486 - accuracy: 0.7909 - val_loss: 0.6753 - val_accuracy: 0.7812\n",
      "Epoch 91/100\n",
      "161/161 [==============================] - 36s 223ms/step - loss: 0.6478 - accuracy: 0.7908 - val_loss: 0.6736 - val_accuracy: 0.7800\n",
      "Epoch 92/100\n",
      "161/161 [==============================] - 38s 239ms/step - loss: 0.6468 - accuracy: 0.7892 - val_loss: 0.6724 - val_accuracy: 0.7808\n",
      "Epoch 93/100\n",
      "161/161 [==============================] - 39s 241ms/step - loss: 0.6466 - accuracy: 0.7889 - val_loss: 0.6722 - val_accuracy: 0.7796\n",
      "Epoch 94/100\n",
      "161/161 [==============================] - 37s 229ms/step - loss: 0.6462 - accuracy: 0.7888 - val_loss: 0.6717 - val_accuracy: 0.7831\n",
      "Epoch 95/100\n",
      "161/161 [==============================] - 36s 222ms/step - loss: 0.6455 - accuracy: 0.7899 - val_loss: 0.6709 - val_accuracy: 0.7808\n",
      "Epoch 96/100\n",
      "161/161 [==============================] - 35s 221ms/step - loss: 0.6452 - accuracy: 0.7901 - val_loss: 0.6712 - val_accuracy: 0.7812\n",
      "Epoch 97/100\n",
      "161/161 [==============================] - 35s 221ms/step - loss: 0.6445 - accuracy: 0.7903 - val_loss: 0.6695 - val_accuracy: 0.7824\n",
      "Epoch 98/100\n",
      "161/161 [==============================] - 34s 210ms/step - loss: 0.6443 - accuracy: 0.7908 - val_loss: 0.6695 - val_accuracy: 0.7827\n",
      "Epoch 99/100\n",
      "161/161 [==============================] - 37s 227ms/step - loss: 0.6433 - accuracy: 0.7903 - val_loss: 0.6697 - val_accuracy: 0.7824\n",
      "Epoch 100/100\n",
      "161/161 [==============================] - 36s 223ms/step - loss: 0.6434 - accuracy: 0.7917 - val_loss: 0.6689 - val_accuracy: 0.7851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29592a83550>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Train the model on new data\n",
    "pretrained_model.fit(X_train_seq, y_train_encoded, batch_size=64, epochs=100, validation_data=(X_val_seq, y_val_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/81 [>.............................] - ETA: 4s"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 6s 72ms/step\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    bình thường       0.83      0.94      0.88       924\n",
      "không liên quan       0.66      0.39      0.49       218\n",
      "         rất tệ       0.33      0.16      0.21        32\n",
      "        rất tốt       0.39      0.11      0.17        64\n",
      "             tệ       0.81      0.72      0.76       567\n",
      "            tốt       0.75      0.85      0.79       768\n",
      "\n",
      "       accuracy                           0.79      2573\n",
      "      macro avg       0.63      0.53      0.55      2573\n",
      "   weighted avg       0.77      0.79      0.77      2573\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = pretrained_model.predict(X_val_seq)\n",
    "# Convert numerical labels to original labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_labels)\n",
    "\n",
    "# Convert true labels to original labels\n",
    "y_val_labels = label_encoder.inverse_transform(y_val)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_val_labels, y_pred_labels)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model.save('../saved_model/Transfer.keras')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
