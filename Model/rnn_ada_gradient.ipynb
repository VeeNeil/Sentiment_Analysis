{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not show feature warning\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from wittgenstein import RIPPER\n",
    "from wittgenstein.interpret import interpret_model, score_fidelity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"dataset_modified.csv\"\n",
    "data = pd.read_csv(src)\n",
    "le = LabelEncoder()\n",
    "for col in data.select_dtypes(include='object'):\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "# View updated dataframe\n",
    "X = data.drop(['Disease'], axis=1)\n",
    "y = data[\"Disease\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "x_train = x_train.to_numpy(dtype='float32')\n",
    "x_test = x_test.to_numpy(dtype='float32')\n",
    "\n",
    "# Convert target data to numpy arrays with int64 data type\n",
    "y_train = y_train.to_numpy(dtype='int64')\n",
    "y_test = y_test.to_numpy(dtype='int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y.nunique()\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(units=32, input_shape=(x_train.shape[1], 1), return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.LSTM(units=16, return_sequences=False),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(units=num_classes, activation='softmax')\n",
    "])\n",
    "rnn_model = KerasClassifier(build_fn=model, epochs=100, batch_size=32, loss=tf.keras.losses.CategoricalCrossentropy())\n",
    "# model.compile(optimizer='Nadam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboost_model = make_pipeline(OneHotEncoder(sparse=False, handle_unknown='use_encoded_value'), AdaBoostClassifier(learning_rate=.1))\n",
    "adaboost_model = AdaBoostClassifier()\n",
    "gradientboost_model = GradientBoostingClassifier(criterion='squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "116/116 [==============================] - 8s 47ms/step - loss: 3.7157\n",
      "Epoch 2/100\n",
      "116/116 [==============================] - 5s 43ms/step - loss: 3.7139\n",
      "Epoch 3/100\n",
      "116/116 [==============================] - 6s 55ms/step - loss: 3.7122\n",
      "Epoch 4/100\n",
      "116/116 [==============================] - 9s 77ms/step - loss: 3.7085\n",
      "Epoch 5/100\n",
      "116/116 [==============================] - 9s 77ms/step - loss: 3.5478\n",
      "Epoch 6/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 3.2043\n",
      "Epoch 7/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 2.9657\n",
      "Epoch 8/100\n",
      "116/116 [==============================] - 10s 84ms/step - loss: 2.7479\n",
      "Epoch 9/100\n",
      "116/116 [==============================] - 10s 83ms/step - loss: 2.5959\n",
      "Epoch 10/100\n",
      "116/116 [==============================] - 10s 85ms/step - loss: 2.4564\n",
      "Epoch 11/100\n",
      "116/116 [==============================] - 10s 85ms/step - loss: 2.3420\n",
      "Epoch 12/100\n",
      "116/116 [==============================] - 10s 83ms/step - loss: 2.2319\n",
      "Epoch 13/100\n",
      "116/116 [==============================] - 10s 85ms/step - loss: 2.1595\n",
      "Epoch 14/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 2.0851\n",
      "Epoch 15/100\n",
      "116/116 [==============================] - 10s 85ms/step - loss: 1.9884\n",
      "Epoch 16/100\n",
      "116/116 [==============================] - 10s 84ms/step - loss: 1.9288\n",
      "Epoch 17/100\n",
      "116/116 [==============================] - 10s 83ms/step - loss: 1.8487\n",
      "Epoch 18/100\n",
      "116/116 [==============================] - 7s 58ms/step - loss: 1.8037\n",
      "Epoch 19/100\n",
      "116/116 [==============================] - 7s 57ms/step - loss: 1.7422\n",
      "Epoch 20/100\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 1.7226\n",
      "Epoch 21/100\n",
      "116/116 [==============================] - 6s 48ms/step - loss: 1.6675\n",
      "Epoch 22/100\n",
      "116/116 [==============================] - 6s 50ms/step - loss: 1.6063\n",
      "Epoch 23/100\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 1.5543\n",
      "Epoch 24/100\n",
      "116/116 [==============================] - 6s 54ms/step - loss: 1.5384\n",
      "Epoch 25/100\n",
      "116/116 [==============================] - 7s 58ms/step - loss: 1.4668\n",
      "Epoch 26/100\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 1.4185\n",
      "Epoch 27/100\n",
      "116/116 [==============================] - 7s 56ms/step - loss: 1.3889\n",
      "Epoch 28/100\n",
      "116/116 [==============================] - 7s 57ms/step - loss: 1.3439\n",
      "Epoch 29/100\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 1.2895\n",
      "Epoch 30/100\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 1.2658\n",
      "Epoch 31/100\n",
      "116/116 [==============================] - 6s 50ms/step - loss: 1.2585\n",
      "Epoch 32/100\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 1.2116\n",
      "Epoch 33/100\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 1.1949\n",
      "Epoch 34/100\n",
      "116/116 [==============================] - 6s 50ms/step - loss: 1.1735\n",
      "Epoch 35/100\n",
      "116/116 [==============================] - 6s 48ms/step - loss: 1.1316\n",
      "Epoch 36/100\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 1.1278\n",
      "Epoch 37/100\n",
      "116/116 [==============================] - 6s 50ms/step - loss: 1.0769\n",
      "Epoch 38/100\n",
      "116/116 [==============================] - 6s 53ms/step - loss: 1.1078\n",
      "Epoch 39/100\n",
      "116/116 [==============================] - 6s 50ms/step - loss: 1.0452\n",
      "Epoch 40/100\n",
      "116/116 [==============================] - 5s 47ms/step - loss: 1.0435\n",
      "Epoch 41/100\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 0.9952\n",
      "Epoch 42/100\n",
      "116/116 [==============================] - 5s 46ms/step - loss: 0.9575\n",
      "Epoch 43/100\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 0.9452\n",
      "Epoch 44/100\n",
      "116/116 [==============================] - 6s 48ms/step - loss: 0.9349\n",
      "Epoch 45/100\n",
      "116/116 [==============================] - 6s 48ms/step - loss: 0.9079\n",
      "Epoch 46/100\n",
      "116/116 [==============================] - 7s 58ms/step - loss: 0.9441\n",
      "Epoch 47/100\n",
      "116/116 [==============================] - 5s 40ms/step - loss: 0.8585\n",
      "Epoch 48/100\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 0.8792\n",
      "Epoch 49/100\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 0.8490\n",
      "Epoch 50/100\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 0.8295\n",
      "Epoch 51/100\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 0.7909\n",
      "Epoch 52/100\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 0.8138\n",
      "Epoch 53/100\n",
      "116/116 [==============================] - 6s 53ms/step - loss: 0.7775\n",
      "Epoch 54/100\n",
      "116/116 [==============================] - 6s 50ms/step - loss: 0.7931\n",
      "Epoch 55/100\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 0.7587\n",
      "Epoch 56/100\n",
      "116/116 [==============================] - 6s 50ms/step - loss: 0.7698\n",
      "Epoch 57/100\n",
      "116/116 [==============================] - 6s 47ms/step - loss: 0.7459\n",
      "Epoch 58/100\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 0.7255\n",
      "Epoch 59/100\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 0.7138\n",
      "Epoch 60/100\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 0.6680\n",
      "Epoch 61/100\n",
      "116/116 [==============================] - 6s 50ms/step - loss: 0.6811\n",
      "Epoch 62/100\n",
      "116/116 [==============================] - 6s 53ms/step - loss: 0.6387\n",
      "Epoch 63/100\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 0.6959\n",
      "Epoch 64/100\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 0.6190\n",
      "Epoch 65/100\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 0.6468\n",
      "Epoch 66/100\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 0.6258\n",
      "Epoch 67/100\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 0.5938\n",
      "Epoch 68/100\n",
      "116/116 [==============================] - 6s 53ms/step - loss: 0.5967\n",
      "Epoch 69/100\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 0.5701\n",
      "Epoch 70/100\n",
      "116/116 [==============================] - 6s 49ms/step - loss: 0.5728\n",
      "Epoch 71/100\n",
      "116/116 [==============================] - 6s 48ms/step - loss: 0.5748\n",
      "Epoch 72/100\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 0.5682\n",
      "Epoch 73/100\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 0.5795\n",
      "Epoch 74/100\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 0.5357\n",
      "Epoch 75/100\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 0.5773\n",
      "Epoch 76/100\n",
      "116/116 [==============================] - 6s 53ms/step - loss: 0.5581\n",
      "Epoch 77/100\n",
      "116/116 [==============================] - 6s 52ms/step - loss: 0.5442\n",
      "Epoch 78/100\n",
      "116/116 [==============================] - 6s 53ms/step - loss: 0.5313\n",
      "Epoch 79/100\n",
      "116/116 [==============================] - 6s 53ms/step - loss: 0.5055\n",
      "Epoch 80/100\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 0.5390\n",
      "Epoch 81/100\n",
      "116/116 [==============================] - 6s 51ms/step - loss: 0.6503\n",
      "Epoch 82/100\n",
      "116/116 [==============================] - 9s 77ms/step - loss: 0.4955\n",
      "Epoch 83/100\n",
      "116/116 [==============================] - 10s 89ms/step - loss: 0.5074\n",
      "Epoch 84/100\n",
      "116/116 [==============================] - 10s 90ms/step - loss: 0.4864\n",
      "Epoch 85/100\n",
      "116/116 [==============================] - 11s 97ms/step - loss: 0.4729\n",
      "Epoch 86/100\n",
      "116/116 [==============================] - 11s 94ms/step - loss: 0.4603\n",
      "Epoch 87/100\n",
      "116/116 [==============================] - 10s 88ms/step - loss: 0.4573\n",
      "Epoch 88/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.5203\n",
      "Epoch 89/100\n",
      "116/116 [==============================] - 9s 77ms/step - loss: 0.4575\n",
      "Epoch 90/100\n",
      "116/116 [==============================] - 9s 82ms/step - loss: 0.4445\n",
      "Epoch 91/100\n",
      "116/116 [==============================] - 9s 80ms/step - loss: 0.4329\n",
      "Epoch 92/100\n",
      "116/116 [==============================] - 9s 78ms/step - loss: 0.4488\n",
      "Epoch 93/100\n",
      "116/116 [==============================] - 10s 82ms/step - loss: 0.4203\n",
      "Epoch 94/100\n",
      "116/116 [==============================] - 9s 79ms/step - loss: 0.4392\n",
      "Epoch 95/100\n",
      "116/116 [==============================] - 7s 61ms/step - loss: 0.3976\n",
      "Epoch 96/100\n",
      "116/116 [==============================] - 7s 57ms/step - loss: 0.3967\n",
      "Epoch 97/100\n",
      "116/116 [==============================] - 6s 53ms/step - loss: 0.4099\n",
      "Epoch 98/100\n",
      "116/116 [==============================] - 7s 58ms/step - loss: 0.3903\n",
      "Epoch 99/100\n",
      "116/116 [==============================] - 7s 60ms/step - loss: 0.4197\n",
      "Epoch 100/100\n",
      "116/116 [==============================] - 6s 54ms/step - loss: 0.3874\n",
      "Epoch 1/100\n",
      "93/93 [==============================] - 7s 46ms/step - loss: 3.7164\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 3.7136\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 6s 65ms/step - loss: 3.7132\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 6s 62ms/step - loss: 3.7115\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 6s 62ms/step - loss: 3.7053\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 7s 73ms/step - loss: 3.5685\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 7s 75ms/step - loss: 3.2901\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 3.0597\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 7s 78ms/step - loss: 2.8787\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 2.7381\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 2.5926\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 2.4720\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 2.3898\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 2.2720\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 7s 81ms/step - loss: 2.1966\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 2.1133\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 2.0508\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 1.9544\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 1.8797\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 7s 80ms/step - loss: 1.8398\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 1.7830\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 1.7302\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 1.7069\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 8s 91ms/step - loss: 1.6333\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 8s 90ms/step - loss: 1.5846\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 1.5476\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 1.5088\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 8s 83ms/step - loss: 1.4470\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 8s 81ms/step - loss: 1.4173\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 8s 86ms/step - loss: 1.3997\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 8s 88ms/step - loss: 1.3848\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 7s 79ms/step - loss: 1.3187\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 7s 72ms/step - loss: 1.2924\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 7s 73ms/step - loss: 1.2217\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 7s 72ms/step - loss: 1.2771\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 1.2670\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 1.3177\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 1.1585\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 1.2253\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 1.1249\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 7s 75ms/step - loss: 1.0929\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 1.0940\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 7s 76ms/step - loss: 1.0769\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 7s 75ms/step - loss: 1.0234\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 7s 73ms/step - loss: 1.0048\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 7s 72ms/step - loss: 1.0066\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 7s 71ms/step - loss: 1.0169\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 0.9485\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 7s 73ms/step - loss: 0.9478\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 0.9272\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 0.9070\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 7s 77ms/step - loss: 0.8733\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 7s 73ms/step - loss: 0.8810\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 0.8375\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 0.8745\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 7s 75ms/step - loss: 0.8126\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 8s 85ms/step - loss: 0.8188\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 8s 85ms/step - loss: 0.8274\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 8s 85ms/step - loss: 0.7954\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 0.7777\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - 8s 87ms/step - loss: 0.8542\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 8s 86ms/step - loss: 0.7459\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 8s 91ms/step - loss: 0.7320\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 8s 91ms/step - loss: 0.7314\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 8s 86ms/step - loss: 0.6960\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - 8s 84ms/step - loss: 0.7303\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - 8s 82ms/step - loss: 0.7185\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - 7s 73ms/step - loss: 0.6733\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.7141\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.6520\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.6440\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - 5s 48ms/step - loss: 0.7027\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.6922\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.6233\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.6272\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.6089\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.6202\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.5643\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.5976\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.5745\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.5340\n",
      "Epoch 82/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.5945\n",
      "Epoch 83/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.5549\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.5349\n",
      "Epoch 85/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.5215\n",
      "Epoch 86/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.5288\n",
      "Epoch 87/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.5321\n",
      "Epoch 88/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.5107\n",
      "Epoch 89/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.5376\n",
      "Epoch 90/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.5106\n",
      "Epoch 91/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.5332\n",
      "Epoch 92/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.4936\n",
      "Epoch 93/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.5373\n",
      "Epoch 94/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.4782\n",
      "Epoch 95/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.4805\n",
      "Epoch 96/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.4735\n",
      "Epoch 97/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.4917\n",
      "Epoch 98/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.4941\n",
      "Epoch 99/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.4705\n",
      "Epoch 100/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.4602\n",
      "24/24 [==============================] - 1s 15ms/step\n",
      "Epoch 1/100\n",
      "93/93 [==============================] - 7s 52ms/step - loss: 3.7160\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 3.7140\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 3.7140\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 3.7121\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 3.7090\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 3.6208\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 3.3562\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 3.1105\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 2.9410\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 6s 61ms/step - loss: 2.7556\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 6s 69ms/step - loss: 2.6402\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 6s 67ms/step - loss: 2.5183\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 6s 68ms/step - loss: 2.4112\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 6s 67ms/step - loss: 2.3337\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 7s 72ms/step - loss: 2.2481\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 7s 70ms/step - loss: 2.1597\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 6s 69ms/step - loss: 2.0946\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 6s 66ms/step - loss: 2.0423\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 6s 65ms/step - loss: 1.9577\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 6s 67ms/step - loss: 1.9279\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.8422\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 6s 64ms/step - loss: 1.7879\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 6s 69ms/step - loss: 1.7244\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 6s 69ms/step - loss: 1.6835\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 7s 70ms/step - loss: 1.6575\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 7s 73ms/step - loss: 2.6352\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 6s 62ms/step - loss: 1.5801\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 1.5338\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 1.4863\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.4509\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 1.4445\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 1.3799\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 1.3510\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 1.3715\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 1.2269\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.1956\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 1.1969\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 1.1267\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 1.0946\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 1.0513\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 1.0543\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.9850\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.9774\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.9756\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.9247\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.9056\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.8644\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.8534\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.8209\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.7921\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 6s 63ms/step - loss: 0.7743\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 6s 61ms/step - loss: 0.7828\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 6s 61ms/step - loss: 0.7855\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.7544\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.7610\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.7085\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.7062\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 4s 43ms/step - loss: 0.6900\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.6480\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 4s 41ms/step - loss: 0.6319\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - 4s 41ms/step - loss: 0.6367\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.6545\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 0.5913\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.6076\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.5745\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.6494\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 0.5692\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - 4s 43ms/step - loss: 0.5861\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.5706\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.5545\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - 4s 43ms/step - loss: 0.5203\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.5151\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.5147\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - 4s 41ms/step - loss: 0.4950\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 0.5118\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 0.5262\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.4931\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.4599\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - 4s 43ms/step - loss: 0.5018\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - 4s 41ms/step - loss: 0.4741\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 0.4909\n",
      "Epoch 82/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.4756\n",
      "Epoch 83/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.4634\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - 11s 115ms/step - loss: 0.4633\n",
      "Epoch 85/100\n",
      "93/93 [==============================] - 4s 43ms/step - loss: 0.4578\n",
      "Epoch 86/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.4429\n",
      "Epoch 87/100\n",
      "93/93 [==============================] - 4s 41ms/step - loss: 0.4144\n",
      "Epoch 88/100\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.4159\n",
      "Epoch 89/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 0.4325\n",
      "Epoch 90/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.4320\n",
      "Epoch 91/100\n",
      "93/93 [==============================] - 4s 43ms/step - loss: 0.4287\n",
      "Epoch 92/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.4098\n",
      "Epoch 93/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.4136\n",
      "Epoch 94/100\n",
      "93/93 [==============================] - 4s 43ms/step - loss: 0.3913\n",
      "Epoch 95/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.3962\n",
      "Epoch 96/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.3631\n",
      "Epoch 97/100\n",
      "93/93 [==============================] - 7s 71ms/step - loss: 0.3823\n",
      "Epoch 98/100\n",
      "93/93 [==============================] - 7s 74ms/step - loss: 0.4850\n",
      "Epoch 99/100\n",
      "93/93 [==============================] - 7s 73ms/step - loss: 0.6115\n",
      "Epoch 100/100\n",
      "93/93 [==============================] - 6s 69ms/step - loss: 0.3528\n",
      "24/24 [==============================] - 1s 22ms/step\n",
      "Epoch 1/100\n",
      "93/93 [==============================] - 9s 67ms/step - loss: 3.7167\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 3.7148\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 3.7127\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 4s 41ms/step - loss: 3.7120\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 3.7068\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 4s 40ms/step - loss: 3.5263\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 3.2594\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 3.0318\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 4s 41ms/step - loss: 2.8519\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 2.7101\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 2.5872\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 2.4797\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 4s 41ms/step - loss: 2.4708\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 4s 43ms/step - loss: 2.5526\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 4s 43ms/step - loss: 2.3387\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 2.1901\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.1717\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.0752\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.0172\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 1.9559\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 1.9113\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 1.8369\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.7820\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 4s 43ms/step - loss: 1.7426\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 1.6940\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 1.6546\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 3.0809\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 1.6366\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 4s 41ms/step - loss: 1.5874\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 1.5563\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 1.4928\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 1.4567\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 4s 41ms/step - loss: 1.4427\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 1.4226\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 1.3236\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.3251\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 1.2702\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 1.2477\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 1.2046\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 4s 43ms/step - loss: 1.2867\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 1.1757\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 1.1347\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 1.0919\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 1.0967\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 1.0671\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 4s 45ms/step - loss: 1.0332\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.0118\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 4s 41ms/step - loss: 1.0000\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.9583\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.9503\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.9097\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.9601\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 0.9222\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 6s 62ms/step - loss: 0.8973\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 6s 63ms/step - loss: 0.8555\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 6s 65ms/step - loss: 0.8075\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 6s 62ms/step - loss: 0.9621\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 6s 60ms/step - loss: 0.7745\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 6s 64ms/step - loss: 0.9112\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 7s 71ms/step - loss: 0.8033\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - 6s 62ms/step - loss: 0.7943\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.8231\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.7320\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.7604\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.7984\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.7461\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.6865\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.7258\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.6657\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.6420\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.6333\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.6863\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.6390\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.6457\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.7214\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.5945\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - 6s 62ms/step - loss: 1.2654\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - 6s 62ms/step - loss: 0.6827\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.7163\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.5949\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.5419\n",
      "Epoch 82/100\n",
      "93/93 [==============================] - 6s 61ms/step - loss: 0.6091\n",
      "Epoch 83/100\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.5592\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.5891\n",
      "Epoch 85/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.5236\n",
      "Epoch 86/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.5514\n",
      "Epoch 87/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.4936\n",
      "Epoch 88/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.5146\n",
      "Epoch 89/100\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5161\n",
      "Epoch 90/100\n",
      "93/93 [==============================] - 5s 58ms/step - loss: 0.5076\n",
      "Epoch 91/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.5001\n",
      "Epoch 92/100\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.7185\n",
      "Epoch 93/100\n",
      "93/93 [==============================] - 6s 69ms/step - loss: 0.4694\n",
      "Epoch 94/100\n",
      "93/93 [==============================] - 6s 65ms/step - loss: 0.4891\n",
      "Epoch 95/100\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.5229\n",
      "Epoch 96/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.4453\n",
      "Epoch 97/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.4975\n",
      "Epoch 98/100\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.4409\n",
      "Epoch 99/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.4363\n",
      "Epoch 100/100\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.4564\n",
      "24/24 [==============================] - 1s 16ms/step\n",
      "Epoch 1/100\n",
      "93/93 [==============================] - 7s 49ms/step - loss: 3.7164\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 3.7150\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 3.7131\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 7s 75ms/step - loss: 3.7131\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 6s 66ms/step - loss: 3.7092\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 6s 59ms/step - loss: 3.6162\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 3.3379\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 3.1126\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 2.9437\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 3.0884\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 2.7457\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.6010\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 2.5239\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 2.3917\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.3285\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 2.2055\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 2.1370\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 2.0731\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 2.1586\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 1.9446\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.9320\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.8888\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.8188\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.7424\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.7124\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.6590\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 1.5977\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 1.5787\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.5182\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.5253\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.4316\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.4152\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 1.4008\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.3561\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.3151\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.3326\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.2786\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.2419\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 1.2217\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.1911\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.1750\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.1593\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.0958\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 1.1108\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.0810\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 1.0606\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 4s 44ms/step - loss: 1.0383\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 1.0103\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.9758\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.9513\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.9886\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.9308\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 5s 48ms/step - loss: 0.8826\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.9926\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.8681\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.8640\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.8380\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.8487\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.8436\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.7796\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.7736\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.7932\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.7715\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.7457\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.7338\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.7440\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.6713\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.6786\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 0.6958\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.6592\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.6466\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 0.6704\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.6921\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.6195\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.6276\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.6087\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.5792\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.6141\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.6038\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.5883\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.5743\n",
      "Epoch 82/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.5610\n",
      "Epoch 83/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.5282\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.5476\n",
      "Epoch 85/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.5351\n",
      "Epoch 86/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.5398\n",
      "Epoch 87/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.5283\n",
      "Epoch 88/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.5036\n",
      "Epoch 89/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.5068\n",
      "Epoch 90/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.5137\n",
      "Epoch 91/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.5060\n",
      "Epoch 92/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.4946\n",
      "Epoch 93/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.4800\n",
      "Epoch 94/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.4922\n",
      "Epoch 95/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.4704\n",
      "Epoch 96/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.4837\n",
      "Epoch 97/100\n",
      "93/93 [==============================] - 5s 53ms/step - loss: 0.4468\n",
      "Epoch 98/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.4492\n",
      "Epoch 99/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.4198\n",
      "Epoch 100/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.4160\n",
      "24/24 [==============================] - 1s 18ms/step\n",
      "Epoch 1/100\n",
      "93/93 [==============================] - 8s 55ms/step - loss: 3.7163\n",
      "Epoch 2/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 3.7149\n",
      "Epoch 3/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 3.7130\n",
      "Epoch 4/100\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 3.7123\n",
      "Epoch 5/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 3.7045\n",
      "Epoch 6/100\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 3.5352\n",
      "Epoch 7/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 3.2653\n",
      "Epoch 8/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 3.0570\n",
      "Epoch 9/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 2.8947\n",
      "Epoch 10/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 2.7704\n",
      "Epoch 11/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 2.6568\n",
      "Epoch 12/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 2.5122\n",
      "Epoch 13/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 2.4534\n",
      "Epoch 14/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 2.3530\n",
      "Epoch 15/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 2.2812\n",
      "Epoch 16/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 2.1980\n",
      "Epoch 17/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 2.1397\n",
      "Epoch 18/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 2.0845\n",
      "Epoch 19/100\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 2.0164\n",
      "Epoch 20/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.9464\n",
      "Epoch 21/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.8894\n",
      "Epoch 22/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.8421\n",
      "Epoch 23/100\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.7489\n",
      "Epoch 24/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.7222\n",
      "Epoch 25/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.6838\n",
      "Epoch 26/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.6361\n",
      "Epoch 27/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.6217\n",
      "Epoch 28/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.5811\n",
      "Epoch 29/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.5211\n",
      "Epoch 30/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.4792\n",
      "Epoch 31/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 1.4619\n",
      "Epoch 32/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.4325\n",
      "Epoch 33/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.3728\n",
      "Epoch 34/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.3993\n",
      "Epoch 35/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.3409\n",
      "Epoch 36/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.3199\n",
      "Epoch 37/100\n",
      "93/93 [==============================] - 5s 59ms/step - loss: 1.3169\n",
      "Epoch 38/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.2998\n",
      "Epoch 39/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.2259\n",
      "Epoch 40/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 1.2452\n",
      "Epoch 41/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.1771\n",
      "Epoch 42/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 1.1940\n",
      "Epoch 43/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.1337\n",
      "Epoch 44/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.1127\n",
      "Epoch 45/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.1092\n",
      "Epoch 46/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 1.0817\n",
      "Epoch 47/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.0926\n",
      "Epoch 48/100\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.0570\n",
      "Epoch 49/100\n",
      "93/93 [==============================] - 5s 57ms/step - loss: 1.0602\n",
      "Epoch 50/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.0072\n",
      "Epoch 51/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 1.0489\n",
      "Epoch 52/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 1.0258\n",
      "Epoch 53/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.9554\n",
      "Epoch 54/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.9389\n",
      "Epoch 55/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.9581\n",
      "Epoch 56/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.9326\n",
      "Epoch 57/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.9240\n",
      "Epoch 58/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.8978\n",
      "Epoch 59/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.8528\n",
      "Epoch 60/100\n",
      "93/93 [==============================] - 5s 55ms/step - loss: 0.8646\n",
      "Epoch 61/100\n",
      "93/93 [==============================] - 5s 56ms/step - loss: 0.8247\n",
      "Epoch 62/100\n",
      "93/93 [==============================] - 6s 62ms/step - loss: 0.8455\n",
      "Epoch 63/100\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.7773\n",
      "Epoch 64/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.8147\n",
      "Epoch 65/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.7887\n",
      "Epoch 66/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.7730\n",
      "Epoch 67/100\n",
      "93/93 [==============================] - 4s 42ms/step - loss: 0.7194\n",
      "Epoch 68/100\n",
      "93/93 [==============================] - 5s 48ms/step - loss: 0.7186\n",
      "Epoch 69/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.7042\n",
      "Epoch 70/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.6930\n",
      "Epoch 71/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.6714\n",
      "Epoch 72/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.7021\n",
      "Epoch 73/100\n",
      "93/93 [==============================] - 4s 46ms/step - loss: 0.6236\n",
      "Epoch 74/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.6130\n",
      "Epoch 75/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.6159\n",
      "Epoch 76/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.6091\n",
      "Epoch 77/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.7025\n",
      "Epoch 78/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.5639\n",
      "Epoch 79/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.5897\n",
      "Epoch 80/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.6481\n",
      "Epoch 81/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.5457\n",
      "Epoch 82/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.5275\n",
      "Epoch 83/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.5055\n",
      "Epoch 84/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.5624\n",
      "Epoch 85/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.5208\n",
      "Epoch 86/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.5179\n",
      "Epoch 87/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.4713\n",
      "Epoch 88/100\n",
      "93/93 [==============================] - 4s 47ms/step - loss: 0.4807\n",
      "Epoch 89/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.4731\n",
      "Epoch 90/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.4713\n",
      "Epoch 91/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.4558\n",
      "Epoch 92/100\n",
      "93/93 [==============================] - 5s 52ms/step - loss: 0.4434\n",
      "Epoch 93/100\n",
      "93/93 [==============================] - 5s 51ms/step - loss: 0.4223\n",
      "Epoch 94/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.4339\n",
      "Epoch 95/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.4160\n",
      "Epoch 96/100\n",
      "93/93 [==============================] - 5s 54ms/step - loss: 0.4116\n",
      "Epoch 97/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.4422\n",
      "Epoch 98/100\n",
      "93/93 [==============================] - 5s 49ms/step - loss: 0.3918\n",
      "Epoch 99/100\n",
      "93/93 [==============================] - 4s 48ms/step - loss: 0.3764\n",
      "Epoch 100/100\n",
      "93/93 [==============================] - 5s 50ms/step - loss: 0.4024\n",
      "24/24 [==============================] - 1s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StackingClassifier(estimators=[(&#x27;adaboost&#x27;, AdaBoostClassifier()),\n",
       "                               (&#x27;rnn&#x27;,\n",
       "                                KerasClassifier(batch_size=32, build_fn=&lt;keras.engine.sequential.Sequential object at 0x000002739F071A10&gt;, epochs=100, loss=&lt;keras.losses.CategoricalCrossentropy object at 0x000002739ED025D0&gt;)),\n",
       "                               (&#x27;gradientboost&#x27;,\n",
       "                                GradientBoostingClassifier(criterion=&#x27;squared_error&#x27;))],\n",
       "                   final_estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StackingClassifier</label><div class=\"sk-toggleable__content\"><pre>StackingClassifier(estimators=[(&#x27;adaboost&#x27;, AdaBoostClassifier()),\n",
       "                               (&#x27;rnn&#x27;,\n",
       "                                KerasClassifier(batch_size=32, build_fn=&lt;keras.engine.sequential.Sequential object at 0x000002739F071A10&gt;, epochs=100, loss=&lt;keras.losses.CategoricalCrossentropy object at 0x000002739ED025D0&gt;)),\n",
       "                               (&#x27;gradientboost&#x27;,\n",
       "                                GradientBoostingClassifier(criterion=&#x27;squared_error&#x27;))],\n",
       "                   final_estimator=LogisticRegression())</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>adaboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rnn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasClassifier</label><div class=\"sk-toggleable__content\"><pre>KerasClassifier(\n",
       "\tmodel=None\n",
       "\tbuild_fn=&lt;keras.engine.sequential.Sequential object at 0x000002739F071A10&gt;\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=&lt;keras.losses.CategoricalCrossentropy object at 0x000002739ED025D0&gt;\n",
       "\tmetrics=None\n",
       "\tbatch_size=32\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=None\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=100\n",
       "\tclass_weight=None\n",
       ")</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>gradientboost</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(criterion=&#x27;squared_error&#x27;)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "StackingClassifier(estimators=[('adaboost', AdaBoostClassifier()),\n",
       "                               ('rnn',\n",
       "                                KerasClassifier(batch_size=32, build_fn=<keras.engine.sequential.Sequential object at 0x000002739F071A10>, epochs=100, loss=<keras.losses.CategoricalCrossentropy object at 0x000002739ED025D0>)),\n",
       "                               ('gradientboost',\n",
       "                                GradientBoostingClassifier(criterion='squared_error'))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_clf = StackingClassifier(estimators=[('adaboost', adaboost_model), ('rnn', rnn_model), ('gradientboost', gradientboost_model)], final_estimator=LogisticRegression())\n",
    "ensemble_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 1s 14ms/step\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        33\n",
      "           3       1.00      1.00      1.00        29\n",
      "           4       1.00      1.00      1.00        29\n",
      "           5       1.00      1.00      1.00        30\n",
      "           6       1.00      1.00      1.00        38\n",
      "           7       1.00      1.00      1.00        29\n",
      "           8       1.00      1.00      1.00        30\n",
      "           9       1.00      1.00      1.00        21\n",
      "          10       1.00      1.00      1.00        29\n",
      "          11       1.00      1.00      1.00        29\n",
      "          12       1.00      1.00      1.00        29\n",
      "          13       1.00      1.00      1.00        37\n",
      "          14       1.00      1.00      1.00        30\n",
      "          15       1.00      1.00      1.00        23\n",
      "          16       1.00      1.00      1.00        37\n",
      "          17       1.00      1.00      1.00        33\n",
      "          18       1.00      1.00      1.00        31\n",
      "          19       1.00      1.00      1.00        38\n",
      "          20       1.00      1.00      1.00        32\n",
      "          21       1.00      1.00      1.00        27\n",
      "          22       1.00      1.00      1.00        39\n",
      "          23       1.00      1.00      1.00        26\n",
      "          24       1.00      1.00      1.00        26\n",
      "          25       1.00      1.00      1.00        32\n",
      "          26       1.00      1.00      1.00        30\n",
      "          27       1.00      1.00      1.00        30\n",
      "          28       1.00      1.00      1.00        28\n",
      "          29       1.00      1.00      1.00        25\n",
      "          30       1.00      1.00      1.00        32\n",
      "          31       1.00      1.00      1.00        23\n",
      "          32       1.00      1.00      1.00        29\n",
      "          33       1.00      1.00      1.00        21\n",
      "          34       1.00      1.00      1.00        34\n",
      "          35       1.00      1.00      1.00        29\n",
      "          36       1.00      1.00      1.00        30\n",
      "          37       1.00      1.00      1.00        25\n",
      "          38       1.00      1.00      1.00        33\n",
      "          39       1.00      1.00      1.00        28\n",
      "          40       1.00      1.00      1.00        37\n",
      "\n",
      "    accuracy                           1.00      1230\n",
      "   macro avg       1.00      1.00      1.00      1230\n",
      "weighted avg       1.00      1.00      1.00      1230\n",
      "\n",
      "Accuracy: \n",
      "1.0\n",
      "Recall: \n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ensemble_clf.predict(x_test)\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Accuracy: \")\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"Recall: \")\n",
    "print(recall_score(y_test, y_pred, average=None))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
