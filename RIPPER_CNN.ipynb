{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-10-10T22:20:53.874528Z",
     "end_time": "2023-10-10T22:20:53.897528Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras.utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.utils import pad_sequences\n",
    "from imblearn.over_sampling import ADASYN\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "data = pd.read_csv('combined_data.csv')\n",
    "\n",
    "# Split the data into features (X) and labels (y)\n",
    "X = data['Nhận xét đánh giá'].values\n",
    "y = data['Cảm xúc'].values\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-10T22:21:28.687027Z",
     "end_time": "2023-10-10T22:21:28.755027Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'bình thường': 3926, 'tốt': 3607, 'tệ': 2993, 'rất tốt': 2604, 'không liên quan': 847, 'rất tệ': 674, 'rất tệ ': 182})\n"
     ]
    }
   ],
   "source": [
    "class_distribution = Counter(y_train)\n",
    "print(class_distribution)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-10T22:21:29.401030Z",
     "end_time": "2023-10-10T22:21:29.434026Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With over-sampling methods, the number of samples in a class should be greater or equal to the original number of samples. Originally, there is 3926 samples and 1191 samples are asked.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 24\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Create the ADASYN sampler with the adjusted sampling strategy\u001B[39;00m\n\u001B[0;32m     23\u001B[0m adasyn \u001B[38;5;241m=\u001B[39m ADASYN(sampling_strategy\u001B[38;5;241m=\u001B[39msampling_strategy_dict, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m---> 24\u001B[0m X_train_resampled, y_train_resampled \u001B[38;5;241m=\u001B[39m \u001B[43madasyn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_resample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_tfidf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m unique_classes \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39munique(y_train_resampled)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnique Classes in y_train_resampled:\u001B[39m\u001B[38;5;124m\"\u001B[39m, unique_classes)\n",
      "File \u001B[1;32mD:\\CODE\\Python\\SentimentalAnalysis\\venv\\lib\\site-packages\\imblearn\\base.py:208\u001B[0m, in \u001B[0;36mBaseSampler.fit_resample\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    187\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Resample the dataset.\u001B[39;00m\n\u001B[0;32m    188\u001B[0m \n\u001B[0;32m    189\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;124;03m    The corresponding label of `X_resampled`.\u001B[39;00m\n\u001B[0;32m    206\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m--> 208\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_resample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\CODE\\Python\\SentimentalAnalysis\\venv\\lib\\site-packages\\imblearn\\base.py:108\u001B[0m, in \u001B[0;36mSamplerMixin.fit_resample\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    105\u001B[0m arrays_transformer \u001B[38;5;241m=\u001B[39m ArraysTransformer(X, y)\n\u001B[0;32m    106\u001B[0m X, y, binarize_y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_X_y(X, y)\n\u001B[1;32m--> 108\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msampling_strategy_ \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_sampling_strategy\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    109\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msampling_strategy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sampling_type\u001B[49m\n\u001B[0;32m    110\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    112\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fit_resample(X, y)\n\u001B[0;32m    114\u001B[0m y_ \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    115\u001B[0m     label_binarize(output[\u001B[38;5;241m1\u001B[39m], classes\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39munique(y)) \u001B[38;5;28;01mif\u001B[39;00m binarize_y \u001B[38;5;28;01melse\u001B[39;00m output[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    116\u001B[0m )\n",
      "File \u001B[1;32mD:\\CODE\\Python\\SentimentalAnalysis\\venv\\lib\\site-packages\\imblearn\\utils\\_validation.py:536\u001B[0m, in \u001B[0;36mcheck_sampling_strategy\u001B[1;34m(sampling_strategy, y, sampling_type, **kwargs)\u001B[0m\n\u001B[0;32m    531\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m OrderedDict(\n\u001B[0;32m    532\u001B[0m         \u001B[38;5;28msorted\u001B[39m(SAMPLING_TARGET_KIND[sampling_strategy](y, sampling_type)\u001B[38;5;241m.\u001B[39mitems())\n\u001B[0;32m    533\u001B[0m     )\n\u001B[0;32m    534\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(sampling_strategy, \u001B[38;5;28mdict\u001B[39m):\n\u001B[0;32m    535\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m OrderedDict(\n\u001B[1;32m--> 536\u001B[0m         \u001B[38;5;28msorted\u001B[39m(\u001B[43m_sampling_strategy_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43msampling_strategy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msampling_type\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mitems())\n\u001B[0;32m    537\u001B[0m     )\n\u001B[0;32m    538\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(sampling_strategy, \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m    539\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m OrderedDict(\n\u001B[0;32m    540\u001B[0m         \u001B[38;5;28msorted\u001B[39m(_sampling_strategy_list(sampling_strategy, y, sampling_type)\u001B[38;5;241m.\u001B[39mitems())\n\u001B[0;32m    541\u001B[0m     )\n",
      "File \u001B[1;32mD:\\CODE\\Python\\SentimentalAnalysis\\venv\\lib\\site-packages\\imblearn\\utils\\_validation.py:314\u001B[0m, in \u001B[0;36m_sampling_strategy_dict\u001B[1;34m(sampling_strategy, y, sampling_type)\u001B[0m\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m class_sample, n_samples \u001B[38;5;129;01min\u001B[39;00m sampling_strategy\u001B[38;5;241m.\u001B[39mitems():\n\u001B[0;32m    313\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m n_samples \u001B[38;5;241m<\u001B[39m target_stats[class_sample]:\n\u001B[1;32m--> 314\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    315\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWith over-sampling methods, the number\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    316\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m of samples in a class should be greater\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    317\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m or equal to the original number of samples.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    318\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m Originally, there is \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtarget_stats[class_sample]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    319\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msamples and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_samples\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m samples are asked.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    320\u001B[0m             )\n\u001B[0;32m    321\u001B[0m         sampling_strategy_[class_sample] \u001B[38;5;241m=\u001B[39m n_samples \u001B[38;5;241m-\u001B[39m target_stats[class_sample]\n\u001B[0;32m    322\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m sampling_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munder-sampling\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mValueError\u001B[0m: With over-sampling methods, the number of samples in a class should be greater or equal to the original number of samples. Originally, there is 3926 samples and 1191 samples are asked."
     ]
    }
   ],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "\n",
    "class_distribution = Counter(y_train)\n",
    "\n",
    "# Define a desired total number of samples (you can adjust this)\n",
    "desired_total_samples = 4500  # Reduce this number\n",
    "\n",
    "# Create the initial sampling strategy\n",
    "sampling_strategy_dict = {\n",
    "    label: int(desired_total_samples * (count / sum(class_distribution.values())))\n",
    "    for label, count in class_distribution.items()\n",
    "}\n",
    "\n",
    "# Ensure that no class exceeds its original count\n",
    "for label, count in class_distribution.items():\n",
    "    if label in sampling_strategy_dict and sampling_strategy_dict[label] > count:\n",
    "        sampling_strategy_dict[label] = count\n",
    "\n",
    "# Create the ADASYN sampler with the adjusted sampling strategy\n",
    "adasyn = ADASYN(sampling_strategy=sampling_strategy_dict, random_state=42)\n",
    "X_train_resampled, y_train_resampled = adasyn.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "unique_classes = np.unique(y_train_resampled)\n",
    "print(\"Unique Classes in y_train_resampled:\", unique_classes)\n",
    "# Tokenization and Padding\n",
    "max_words = 5000\n",
    "max_len = 1000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "\n",
    "X_train_seq = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_val_seq = pad_sequences(X_val_seq, maxlen=max_len)\n",
    "\n",
    "# Build and compile your CNN model\n",
    "embedding_dim = 120\n",
    "num_filters = 128\n",
    "kernel_size = 5\n",
    "num_classes = len(label_encoder.classes_)\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length=max_len))\n",
    "model.add(Conv1D(num_filters, kernel_size, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T06:53:47.754675Z",
     "end_time": "2023-10-08T06:53:58.220053Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T06:53:58.205054Z",
     "end_time": "2023-10-08T06:53:58.467050Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the model\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "model.fit(X_train_seq, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val_seq, y_val))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T06:53:58.470052Z",
     "end_time": "2023-10-08T07:07:03.497468Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_val_seq, y_val)\n",
    "print(f\"Validation loss: {loss}\")\n",
    "print(f\"Validation accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T07:07:03.475464Z",
     "end_time": "2023-10-08T07:07:07.924465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val_seq)\n",
    "# Convert numerical labels to original labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred_labels)\n",
    "\n",
    "# Convert true labels to original labels\n",
    "y_val_labels = label_encoder.inverse_transform(y_val)\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_val_labels, y_pred_labels)\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-08T07:07:53.935355Z",
     "end_time": "2023-10-08T07:07:57.982356Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
